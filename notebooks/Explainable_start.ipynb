{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwitschel/HCIBM/blob/main/notebooks/Explainable_start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Execute this code only if in colab\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "  print(\"Executing in Colab!\")\n",
        "  # Cloning GitHub repository\n",
        "  !git clone https://github.com/fwitschel/HCIBM.git\n",
        "  %cd HCIBM\n"
      ],
      "metadata": {
        "id": "qRHf7ZEBbs5-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "e11dSSgXh8uu"
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "!pip install imodels\n",
        "\n",
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn import tree\n",
        "from imodels import RuleFitRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "# UnterdrÃ¼ckt spezifisch Deprecation-Warnungen\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "data = pd.read_csv('/content/HCIBM/datasets/Myocardial infarction complications Database.csv')\n",
        "\n",
        "# remove the columns corresponding to other complications that we do not want to predict\n",
        "data = data.drop('KFK_BLOOD', axis=1)\n",
        "data = data.drop('IBS_NASL', axis=1)\n",
        "data = data.drop('LET_IS', axis=1)\n",
        "data = data.drop('P_IM_STEN', axis=1)\n",
        "data = data.drop('REC_IM', axis=1)\n",
        "data = data.drop('DRESSLER', axis=1)\n",
        "data = data.drop('RAZRIV', axis=1)\n",
        "data = data.drop('OTEK_LANC', axis=1)\n",
        "data = data.drop('A_V_BLOK', axis=1)\n",
        "data = data.drop('FIBR_JELUD', axis=1)\n",
        "data = data.drop('JELUD_TAH', axis=1)\n",
        "data = data.drop('PREDS_TAH', axis=1)\n",
        "data = data.drop('FIBR_PREDS', axis=1)\n",
        "data = data.drop('ID', axis=1)\n",
        "\n",
        "# we additionally drop some columns where a lot of values are missing\n",
        "# (makes performance of models better...)\n",
        "data = data.drop('S_AD_KBRIG', axis=1)\n",
        "data = data.drop('D_AD_KBRIG', axis=1)\n",
        "data = data.drop('NOT_NA_KB', axis=1)\n",
        "data = data.drop('LID_KB', axis=1)\n",
        "data = data.drop('NA_KB', axis=1)\n",
        "data = data.drop('GIPO_K', axis=1)\n",
        "\n",
        "X = data.drop('ZSN', axis=1)\n",
        "one_hot_X = pd.get_dummies(X)\n",
        "y = data.ZSN"
      ],
      "metadata": {
        "id": "wRH3ZpEaiVh3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(one_hot_X, y, test_size=0.2)\n",
        "model = XGBClassifier(n_estimators = 42, max_depth = 5)\n",
        "\n",
        "# A central problem with RuleFit is that it cannot deal with missing values - whereas XGBoost can...\n",
        "# here, we will handle this by replacing missing values with a special constant\n",
        "# -> you can check that it has very minor influence on performance...!\n",
        "X_train_const = X_train.fillna(-999)\n",
        "X_test_const = X_test.fillna(-999)\n",
        "model.fit(X_train_const.values, y_train.values)"
      ],
      "metadata": {
        "id": "Q-a7M3RKiWte",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model quickly:\n",
        "y_probs = model.predict_proba(X_test_const)[:, 1]\n",
        "auc_score = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC score on test set: {auc_score:.4f}\")"
      ],
      "metadata": {
        "id": "5uTkwG49-FHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use not the hard predictions (0 or 1), but the predicted probabilities\n",
        "# note: this becomes a regression task now!!\n",
        "y_sur = model.predict_proba(X_train_const)[:, 1]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XiRvJAMpnb5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if hasattr(X_train, \"columns\"):\n",
        "  feature_names = list(X_train_const.columns)\n",
        "else:\n",
        "  feature_names = [f\"x{i}\" for i in range(X_train_const.shape[1])]\n",
        "\n",
        "# 3. Training on predicted probabilities\n",
        "# --- fit RuleFit surrogate ---\n",
        "rf = RuleFitRegressor(\n",
        "    n_estimators=35,          # number of trees used to generate candidate rules\n",
        "    max_rules=300,       # cap on number of extracted rules\n",
        "    tree_size=5,               # avg depth-ish; higher -> more complex rules\n",
        "    random_state=42,\n",
        "    include_linear=True,       # include linear terms too (we'll filter them later)\n",
        "    exp_rand_tree_size=True,   # varied tree sizes helps rule diversity\n",
        ")\n",
        "rf.fit(X_train_const, y_sur, feature_names=feature_names)\n",
        "\n",
        "# Optional quick sanity check of surrogate fidelity (on eval set if given)\n",
        "if X_test is not None:\n",
        "    y_xgb_pred = model.predict_proba(X_test_const)[:, 1]\n",
        "    y_rf_pred = rf.predict(X_test_const.values).flatten()\n",
        "    r2 = r2_score(y_xgb_pred, y_rf_pred)\n",
        "    print(f\"Fidelity: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "8SVwmzE8oZtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- extract and rank rules ---\n",
        "df_rules = rf._get_rules()\n",
        "df_plot = df_rules[df_rules.coef != 0].sort_values(\"importance\", ascending=False).head(20)\n",
        "\n",
        "# 3. Visualisation\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Colors in our bar chart:\n",
        "# red = rule increases predicted probability\n",
        "# blue = rule decreases prediction\n",
        "colors = ['#2c7bb6' if c < 0 else '#d7191c' for c in df_plot['coef']]\n",
        "\n",
        "# note: importance is a mixture between the size of the coefficient and frequency of the rule\n",
        "# where middle frequencies are considered most interesting\n",
        "# \\(I_{j}=|\\^{a}_{j}|\\cdot \\sqrt{s_{j}\\cdot (1-s_{j})}\\)\n",
        "# with a_j = coefficients and s_j = support values\n",
        "sns.barplot(\n",
        "    data=df_plot,\n",
        "    x=\"importance\",\n",
        "    y=\"rule\",\n",
        "    palette=colors\n",
        ")\n",
        "\n",
        "plt.title(\"Top 20 Rules explaining your XGBoost Model\", fontsize=15)\n",
        "plt.xlabel(\"Importance (Impact on Model Predictions)\", fontsize=12)\n",
        "plt.ylabel(\"Rule Condition\", fontsize=12)\n",
        "plt.axvline(0, color='black', lw=1)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ra2-3eB-5EaT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}